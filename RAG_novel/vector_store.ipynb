{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vector_store.ipynb\n",
    "- data/소설들.pdf 들  vector store에 저장.\n",
    "    - chroma, pinecone\n",
    "    - metadata\n",
    "        - title : 소설제목\n",
    "        - author : 저자\n",
    "        - full_text : 소설 전체 내용\n",
    "    - Document(page_content=\"split된 내용\", metadata={})\n",
    "    - page_content는 조회할 떄 사용할 embedding vector를 생성할 때 사용될 내용.\n",
    "    - LLM 모델에 전송할 context는 metadata의 full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The MIME type of 'data\\\\금_따는_콩밭_김유정.pdf' is \"cannot open `data\\\\\\\\352\\\\270\\\\210_\\\\353\\\\224\\\\260\\\\353\\\\212\\\\224_\\\\354\\\\275\\\\251\\\\353\\\\260\\\\255_\\\\352\\\\271\\\\200\\\\354\\\\234\\\\240\\\\354\\\\240\\\\225.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The MIME type of 'data\\\\동백꽃_김유정.pdf' is \"cannot open `data\\\\\\\\353\\\\217\\\\231\\\\353\\\\260\\\\261\\\\352\\\\275\\\\203_\\\\352\\\\271\\\\200\\\\354\\\\234\\\\240\\\\354\\\\240\\\\225.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\메밀꽃_필_무렵_이효석.pdf' is \"cannot open `data\\\\\\\\353\\\\251\\\\224\\\\353\\\\260\\\\200\\\\352\\\\275\\\\203_\\\\355\\\\225\\\\204_\\\\353\\\\254\\\\264\\\\353\\\\240\\\\265_\\\\354\\\\235\\\\264\\\\355\\\\232\\\\250\\\\354\\\\204\\\\235.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\배따라기_김동인.pdf' is \"cannot open `data\\\\\\\\353\\\\260\\\\260\\\\353\\\\224\\\\260\\\\353\\\\235\\\\274\\\\352\\\\270\\\\260_\\\\352\\\\271\\\\200\\\\353\\\\217\\\\231\\\\354\\\\235\\\\270.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\백치_아다다_계용묵.pdf' is \"cannot open `data\\\\\\\\353\\\\260\\\\261\\\\354\\\\271\\\\230_\\\\354\\\\225\\\\204\\\\353\\\\213\\\\244\\\\353\\\\213\\\\244_\\\\352\\\\263\\\\204\\\\354\\\\232\\\\251\\\\353\\\\254\\\\265.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\벙어리_삼룡이_나도향.pdf' is \"cannot open `data\\\\\\\\353\\\\262\\\\231\\\\354\\\\226\\\\264\\\\353\\\\246\\\\254_\\\\354\\\\202\\\\274\\\\353\\\\243\\\\241\\\\354\\\\235\\\\264_\\\\353\\\\202\\\\230\\\\353\\\\217\\\\204\\\\355\\\\226\\\\245.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\봄봄_김유정.pdf' is \"cannot open `data\\\\\\\\353\\\\264\\\\204\\\\353\\\\264\\\\204_\\\\352\\\\271\\\\200\\\\354\\\\234\\\\240\\\\354\\\\240\\\\225.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\소나기.pdf' is \"cannot open `data\\\\\\\\354\\\\206\\\\214\\\\353\\\\202\\\\230\\\\352\\\\270\\\\260.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\술_권하는_사회_현진건.pdf' is \"cannot open `data\\\\\\\\354\\\\210\\\\240_\\\\352\\\\266\\\\214\\\\355\\\\225\\\\230\\\\353\\\\212\\\\224_\\\\354\\\\202\\\\254\\\\355\\\\232\\\\214_\\\\355\\\\230\\\\204\\\\354\\\\247\\\\204\\\\352\\\\261\\\\264.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\운수_좋은_날_현진건.pdf' is \"cannot open `data\\\\\\\\354\\\\232\\\\264\\\\354\\\\210\\\\230_\\\\354\\\\242\\\\213\\\\354\\\\235\\\\200_\\\\353\\\\202\\\\240_\\\\355\\\\230\\\\204\\\\354\\\\247\\\\204\\\\352\\\\261\\\\264.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "# 1. Directory Loader 객체 생성 -> loading할 문서(들)을 지정.\n",
    "loader = DirectoryLoader(\n",
    "    path=\"./data\", \n",
    "    glob=[\"*.pdf\"],\n",
    "    recursive=True,    \n",
    ")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The MIME type of 'data\\\\금_따는_콩밭_김유정.pdf' is \"cannot open `data\\\\\\\\352\\\\270\\\\210_\\\\353\\\\224\\\\260\\\\353\\\\212\\\\224_\\\\354\\\\275\\\\251\\\\353\\\\260\\\\255_\\\\352\\\\271\\\\200\\\\354\\\\234\\\\240\\\\354\\\\240\\\\225.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The MIME type of 'data\\\\동백꽃_김유정.pdf' is \"cannot open `data\\\\\\\\353\\\\217\\\\231\\\\353\\\\260\\\\261\\\\352\\\\275\\\\203_\\\\352\\\\271\\\\200\\\\354\\\\234\\\\240\\\\354\\\\240\\\\225.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\메밀꽃_필_무렵_이효석.pdf' is \"cannot open `data\\\\\\\\353\\\\251\\\\224\\\\353\\\\260\\\\200\\\\352\\\\275\\\\203_\\\\355\\\\225\\\\204_\\\\353\\\\254\\\\264\\\\353\\\\240\\\\265_\\\\354\\\\235\\\\264\\\\355\\\\232\\\\250\\\\354\\\\204\\\\235.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\배따라기_김동인.pdf' is \"cannot open `data\\\\\\\\353\\\\260\\\\260\\\\353\\\\224\\\\260\\\\353\\\\235\\\\274\\\\352\\\\270\\\\260_\\\\352\\\\271\\\\200\\\\353\\\\217\\\\231\\\\354\\\\235\\\\270.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\백치_아다다_계용묵.pdf' is \"cannot open `data\\\\\\\\353\\\\260\\\\261\\\\354\\\\271\\\\230_\\\\354\\\\225\\\\204\\\\353\\\\213\\\\244\\\\353\\\\213\\\\244_\\\\352\\\\263\\\\204\\\\354\\\\232\\\\251\\\\353\\\\254\\\\265.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\벙어리_삼룡이_나도향.pdf' is \"cannot open `data\\\\\\\\353\\\\262\\\\231\\\\354\\\\226\\\\264\\\\353\\\\246\\\\254_\\\\354\\\\202\\\\274\\\\353\\\\243\\\\241\\\\354\\\\235\\\\264_\\\\353\\\\202\\\\230\\\\353\\\\217\\\\204\\\\355\\\\226\\\\245.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\봄봄_김유정.pdf' is \"cannot open `data\\\\\\\\353\\\\264\\\\204\\\\353\\\\264\\\\204_\\\\352\\\\271\\\\200\\\\354\\\\234\\\\240\\\\354\\\\240\\\\225.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\소나기.pdf' is \"cannot open `data\\\\\\\\354\\\\206\\\\214\\\\353\\\\202\\\\230\\\\352\\\\270\\\\260.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\술_권하는_사회_현진건.pdf' is \"cannot open `data\\\\\\\\354\\\\210\\\\240_\\\\352\\\\266\\\\214\\\\355\\\\225\\\\230\\\\353\\\\212\\\\224_\\\\354\\\\202\\\\254\\\\355\\\\232\\\\214_\\\\355\\\\230\\\\204\\\\354\\\\247\\\\204\\\\352\\\\261\\\\264.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n",
      "The MIME type of 'data\\\\운수_좋은_날_현진건.pdf' is \"cannot open `data\\\\\\\\354\\\\232\\\\264\\\\354\\\\210\\\\230_\\\\354\\\\242\\\\213\\\\354\\\\235\\\\200_\\\\353\\\\202\\\\240_\\\\355\\\\230\\\\204\\\\354\\\\247\\\\204\\\\352\\\\261\\\\264.pdf' (illegal byte sequence)\". This file type is not currently supported in unstructured.\n"
     ]
    }
   ],
   "source": [
    "# 2. RecursiveCharacterTextSplitter 객체 생성 -> Document를 분할.\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100)\n",
    "\n",
    "split_docs = splitter.split_documents(docs)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0)\n",
    "\n",
    "docs = loader.load_and_split(splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 메타데이터 추출 함수\n",
    "def extract_metadata(pdf_path):\n",
    "    # 여기에 소설 제목과 저자 추출 로직을 추가하세요.\n",
    "    # 예제: 파일명에서 제목과 저자 추출\n",
    "    filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    parts = filename.split(\"_\")\n",
    "    title = parts[0] if len(parts) > 0 else \"Unknown Title\"\n",
    "    author = parts[1] if len(parts) > 1 else \"Unknown Author\"\n",
    "    return title, author\n",
    "\n",
    "# 전체 텍스트 가져오기 함수\n",
    "def get_full_text(documents):\n",
    "    return \"\".join([doc.page_content for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'text': 'Document' object cannot be converted to 'PyString'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m embedding_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39membedding_model_name)\n\u001b[1;32m----> 8\u001b[0m embedding_docs \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(embedding_docs))\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:480\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mGenerate length-safe embeddings for a list of texts.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03m    List[List[float]]: A list of embeddings for each input text.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    479\u001b[0m _chunk_size \u001b[38;5;241m=\u001b[39m chunk_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size\n\u001b[1;32m--> 480\u001b[0m _iter, tokens, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:441\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._tokenize\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    439\u001b[0m     token \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mencode(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[43mencoding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_ordinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Split tokens into chunks respecting the embedding_ctx_length\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(token), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ctx_length):\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\\tiktoken\\core.py:69\u001b[0m, in \u001b[0;36mEncoding.encode_ordinary\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Encodes a string into tokens, ignoring special tokens.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03mThis is equivalent to `encode(text, disallowed_special=())` (but slightly faster).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m[31373, 995]\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core_bpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_ordinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# See comment in encode\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'text': 'Document' object cannot be converted to 'PyString'"
     ]
    }
   ],
   "source": [
    "# 3. OpenAIEmbeddings 객체 생성 -> embedding vector를 생성.\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model_name = \"text-embedding-3-small\"\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=embedding_model_name)\n",
    "\n",
    "embedding_docs = embedding_model.embed_documents(--)\n",
    "print(len(embedding_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINECONE_API_KEY를 활용한 vector store\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "COLLECTION_NAME = \"RAG_novel\"\n",
    "PERSIST_DIRECTORY = \"vector_store/chroma/RAG_novel_db\"  # 저장할 경로\n",
    "\n",
    "# 저장하면서 생성\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_list,\n",
    "    embedding=embedding_model,\n",
    "    ids= ids,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")\n",
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "COLLECTION_NAME = \"RAG_novel_db_openai\"\n",
    "PERSIST_DIRECTORY = \"vector_store/chroma/RAG_novel_db\"\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-3-small\"\n",
    "embedding_model = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")\n",
    "retriever = vector_store.as_retriever()\n",
    "query = \"\"\n",
    "result = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- app.py\n",
    "    - steamlit을 이용해서 서비스하는 application\n",
    "    - vector_store.ipynb에서 구축한 DB를 이용해 질문과 관련된 내용들을 조회해서 LLM에 전송하고 그 결과를 채팅창에 출력.\n",
    "    - memory 기능은 사용하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "# Pinecone API 초기화\n",
    "pinecone.init(api_key=\"your-pinecone-api-key\", environment=\"your-pinecone-environment\")\n",
    "\n",
    "# 데이터 폴더 설정\n",
    "data_folder = \"data/\"\n",
    "file_paths = [os.path.join(data_folder, file) for file in os.listdir(data_folder) if file.endswith(\".pdf\")]\n",
    "\n",
    "# 텍스트 분할 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # 청크 크기 설정\n",
    "    chunk_overlap=100  # 청크 간 중복 설정\n",
    ")\n",
    "\n",
    "# 메타데이터 추출 함수\n",
    "def extract_metadata(pdf_path):\n",
    "    # 파일명에서 제목과 저자 추출 (예: \"소설제목_저자.pdf\")\n",
    "    filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    parts = filename.split(\"_\")\n",
    "    title = parts[0] if len(parts) > 0 else \"Unknown Title\"\n",
    "    author = parts[1] if len(parts) > 1 else \"Unknown Author\"\n",
    "    return title, author\n",
    "\n",
    "# 전체 텍스트 가져오기 함수\n",
    "def get_full_text(documents):\n",
    "    return \"\".join([doc.page_content for doc in documents])\n",
    "\n",
    "# 문서 처리 및 벡터 스토어에 저장\n",
    "all_split_docs = []\n",
    "for file_path in file_paths:\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    title, author = extract_metadata(file_path)\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    full_text = get_full_text(documents)\n",
    "    for doc in split_docs:\n",
    "        doc.metadata.update({\n",
    "            \"title\": title,\n",
    "            \"author\": author,\n",
    "            \"full_text\": full_text  # 소설 전체 내용\n",
    "        })\n",
    "    all_split_docs.extend(split_docs)\n",
    "\n",
    "# 벡터 스토어 생성 - Chroma\n",
    "chroma_store = Chroma(\n",
    "    collection_name=\"novels\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "chroma_store.add_documents(all_split_docs)\n",
    "\n",
    "# 벡터 스토어 생성 - Pinecone\n",
    "pinecone_index_name = \"novels-index\"\n",
    "if pinecone_index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        name=pinecone_index_name,\n",
    "        dimension=OpenAIEmbeddings().dimension\n",
    "    )\n",
    "pinecone_store = Pinecone(\n",
    "    index=pinecone.Index(pinecone_index_name),\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "pinecone_store.add_documents(all_split_docs)\n",
    "\n",
    "print(\"Vector store 저장 완료!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
