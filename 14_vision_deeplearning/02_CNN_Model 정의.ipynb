{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1-HdRR266M6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d 생성\n",
    "layer = nn.Conv2d(\n",
    "    in_channels=3,   # 입력 데이터의 channel 개수. 입력 tensor 의 shape: (batch_size, channel, height, width)\n",
    "    out_channels=5,  # 필터의 개수, (output feature map의 개수)\n",
    "    kernel_size=3,   # 필터의 크기를 지정함.(3, 3 = 3 X 3)\n",
    "    # 3가지 설정은 필수 지정 사항.\n",
    "    stride=1,        # 계산을 위해 이동하는 크기. 좌->우 : 1칸씩 , 상->하: 1칸씩 이동 (default: 1) \n",
    "    padding=0,       # 패딩 크기 (정수: 상하/좌우 동일한 패딩크기를 명시 - 0 (default) : 패딩을 추가하지 않음.)    \n",
    "                     # \"same\": 입력 size 와 동일한 size의 출력이 나오도록 알아서 패딩을 추가함.\n",
    ")\n",
    "# # 다음 layer 생성\n",
    "# layer2 = nn.Cov2d(\n",
    "#     in_channels=5, # (이전 Conv2'의 out_channels 값이 다음 Conv2'의 in_channels 값이 된다.)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 8, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.ones(1, 3, 10, 10)  # batch size, channel 수, height, width\n",
    "output = layer(input_data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10 - 3 + 2 * 0)/1 +1    # (10 - kernel + 2 * padding)/stride +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Conv2d의 weigh의 shape.\n",
    "layer.weight.shape\n",
    "# [5:필터개수-out_channels,  \n",
    "#  3:channel수-in_channel,  \n",
    "#  3:height-kernel_size,  \n",
    "#  3:width-kernel_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias.shape  # channel 당 1개씩 bias 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = nn.MaxPool2d(\n",
    "    kernel_size=2,  # 값을 추출하는 영역 크기(2, 2) - default: 2\n",
    "    stride=2,       # 다음 값을 추출하기 위해서 몇칸을 이동할지 지정함. (default: kernel_size)\n",
    "    padding=0,      # 값을 추출할 영역이 kernel_size보다 작을 경우 추출할지 여부. (-- 추출 안함.)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 10, 10])\n",
      "torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)\n",
    "pool_output = pool_layer(input_data)\n",
    "print(pool_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn(1, 1, 5, 5)\n",
    "\n",
    "print(input_data.shape)\n",
    "pool_output = pool_layer(input_data)\n",
    "print(pool_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3085,  1.3471,  0.5306,  1.1917,  0.1289],\n",
       "        [ 1.3115, -1.1110, -0.2047,  2.3603,  0.1377],\n",
       "        [-0.3777, -1.1396,  1.3689,  0.4415,  1.2804],\n",
       "        [ 0.5678, -0.3815, -0.8584, -0.7741,  0.9000],\n",
       "        [ 1.1591, -0.3105, -1.2150,  0.8543,  2.0922]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.3471, 2.3603],\n",
       "          [0.5678, 1.3689]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Using cached torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Using cached torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from module.data import load_mnist_dataset, load_fashion_mnist_dataset\n",
    "from module.train import fit\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter 지정\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DATA_ROOT_DIR = \"datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 95.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.55MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = load_mnist_dataset(DATA_ROOT_DIR, BATCH_SIZE, True)\n",
    "test_loader = load_mnist_dataset(DATA_ROOT_DIR, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "# ConvolutionLayer -> Activation -> Pooling Layer\n",
    "# ConvolutionLayer -> Activation -> ConvolutionLayer -> Activation -> Pooling Layer\n",
    "\n",
    "# ConvolutionLayer -> BatchNormalization -> Activation -> Dropout -> Pooling Layer\n",
    "\n",
    "## Layer 구조 : filter개수는 늘려주고, feature map의 size는 줄이는 방식으로 구성.\n",
    "# depth:  Conv2d,  Size : MaxPool2d\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        # Model 을 구성하는 Layer 함수들을 초기화(객체 생성)\n",
    "        super().__init__()\n",
    "        # block 단위로 정의 - nn.Sequential()\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,   # grayscale 이미지 -> channel수:1, color:3(RGB입력)\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,  # default 값이 1이므로, 생략가능함.\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),   # Conv: out_channels\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,   # b1 채널의 개수(out_channels 값)\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),   # Conv: out_channels\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,   # b2 채널의 개수(out_channels 값)\n",
    "                out_channels=128, # 유지하거나, 늘릴수 있음.\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),   # Conv: out_channels\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # 추론기(분류기) - Fully Connected Layer(nn.Linear)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=4*4*128, out_features=10)  # 최종 결과를 반환할 Layer\n",
    "            # out_features= class 개수\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 추론(연산처리) - X : 입력 image\n",
    "        output = self.b1(X)\n",
    "        output = self.b2(output)\n",
    "        output = self.b3(output)        # 마지막 conb block -> output: Feature vector\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (b1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (b2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (b3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNModel(dropout_rate=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNModel                                 [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 28, 28]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 28, 28]           --\n",
       "│    └─Dropout: 2-4                      [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 32, 14, 14]           --\n",
       "├─Sequential: 1-2                        [1, 64, 7, 7]             --\n",
       "│    └─Conv2d: 2-6                       [1, 64, 14, 14]           18,496\n",
       "│    └─BatchNorm2d: 2-7                  [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-8                         [1, 64, 14, 14]           --\n",
       "│    └─Dropout: 2-9                      [1, 64, 14, 14]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-3                        [1, 128, 4, 4]            --\n",
       "│    └─Conv2d: 2-11                      [1, 128, 7, 7]            73,856\n",
       "│    └─BatchNorm2d: 2-12                 [1, 128, 7, 7]            256\n",
       "│    └─ReLU: 2-13                        [1, 128, 7, 7]            --\n",
       "│    └─Dropout: 2-14                     [1, 128, 7, 7]            --\n",
       "│    └─MaxPool2d: 2-15                   [1, 128, 4, 4]            --\n",
       "├─Sequential: 1-4                        [1, 10]                   --\n",
       "│    └─Flatten: 2-16                     [1, 2048]                 --\n",
       "│    └─Linear: 2-17                      [1, 10]                   20,490\n",
       "==========================================================================================\n",
       "Total params: 113,610\n",
       "Trainable params: 113,610\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 7.52\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.70\n",
       "Params size (MB): 0.45\n",
       "Estimated Total Size (MB): 1.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, (1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "model = model.to(device)\n",
    "\n",
    "# loss 함수\n",
    "loss_fn = nn.CrossEntropyLoss() # 정답: One hot encoding처리, 추론: Softmax 적용\n",
    "\n",
    "# Optimazer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"saved_models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/1] - Train loss: 0.48161 Train Accucracy: 0.97232 || Validation Loss: 0.47219 Validation Accuracy: 0.97530\n",
      "====================================================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory save_model does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_model/mnist_cnn_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\Documents\\class\\homework\\14_vision_deeplearning\\module\\train.py:174\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(train_loader, val_loader, model, loss_fn, optimizer, epochs, save_best_model, save_model_path, early_stopping, patience, device, mode, lr_scheduler)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_best_model:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_score_save:\n\u001b[1;32m--> 174\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m저장: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - 이전 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score_save\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 현재: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    176\u001b[0m         best_score_save \u001b[38;5;241m=\u001b[39m val_loss\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\\torch\\serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    850\u001b[0m         _save(\n\u001b[0;32m    851\u001b[0m             obj,\n\u001b[0;32m    852\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    856\u001b[0m         )\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\\torch\\serialization.py:716\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\\torch\\serialization.py:687\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory save_model does not exist."
     ]
    }
   ],
   "source": [
    "save_path = \"saved_models/mnist_cnn_model.pt\"\n",
    "result = fit(\n",
    "    train_loader, test_loader, model, loss_fn, optimizer, EPOCH, save_model_path=save_path, device=device, mode=\"multi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.472193618118763, 0.9753)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 평가\n",
    "from module.train import test_multi_classification\n",
    "loss, acc = test_multi_classification(\n",
    "    test_loader, model, loss_fn, device\n",
    ")\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (11.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 정성적 평가 - 실제 image 파일로 확인\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open(\"test_img/num/eight.png\")\n",
    "type(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def predict(path, model):\n",
    "    img = Image.open(path)\n",
    "\n",
    "    # color(3) -> grayscale(1)\n",
    "    img = img.convert('L')  # 'L' : grayscale, \"RGB\": color\n",
    "\n",
    "    # resize\n",
    "    input_tensor = transforms.Resize((28, 28))(img)\n",
    "\n",
    "    # PIL.Image -> torch.Tensor  변환, 정규화 (0 ~ 1)\n",
    "    input_tensor = transforms.ToTensor()(input_tensor)\n",
    "\n",
    "    #batch축(dummy 축) 추가\n",
    "    input_tensor = input_tensor.unsqueeze(dim=0)\n",
    "\n",
    "    # print(type(input_tensor))\n",
    "    # input_tensor.shape\n",
    "    with torch.no_grad():\n",
    "        result = model(input_tensor)\n",
    "    sm = nn.Softmax(dim=-1)\n",
    "    result_proba = sm(result)\n",
    "    final_result = result_proba.max(dim=-1)\n",
    "    return {\"class\":final_result.indices[0], \"확률\":final_result.values[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_img/num\\eight.png, 추론class:8, 확률: 0.17167770862579346\n",
      "test_img/num\\eight2.png, 추론class:8, 확률: 0.32744091749191284\n",
      "test_img/num\\five.png, 추론class:5, 확률: 0.3569532632827759\n",
      "test_img/num\\four.png, 추론class:4, 확률: 0.5325490236282349\n",
      "test_img/num\\one.png, 추론class:1, 확률: 0.4972973167896271\n",
      "test_img/num\\seven.png, 추론class:1, 확률: 0.25710904598236084\n",
      "test_img/num\\seven2.png, 추론class:1, 확률: 0.4450855851173401\n",
      "test_img/num\\three.png, 추론class:3, 확률: 0.3694651424884796\n",
      "test_img/num\\three2.png, 추론class:3, 확률: 0.48430269956588745\n",
      "test_img/num\\two.png, 추론class:2, 확률: 0.5145750641822815\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "img_path_list = glob(\"test_img/num/*.png\")\n",
    "for img_path in img_path_list:\n",
    "    result = predict(img_path, model)\n",
    "    print(f\"{img_path}, 추론class:{result['class']}, 확률: {result['확률']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2ARCyjDW66NR",
    "6bAN1wPG66NS",
    "shNUg6al66NV",
    "7xgQxAU666NZ"
   ],
   "name": "07_CNN_MNIST분류, 모델저장.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
