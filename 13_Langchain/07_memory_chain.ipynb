{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9651606d-6aa2-424c-9b7a-f3ef725e844a",
   "metadata": {},
   "source": [
    "# RunnableWithMessageHistory\n",
    "\n",
    "**RunnableWithMessageHistory**는 대화형 애플리케이션에서 메시지 기록을 관리하고, 이를 기반으로 상태를 유지하며 대화를 이어갈 수 있도록 돕는 클래스이다. 사용자와 AI 간의 대화에서 이전 대화의 맥락을 유지해야 할 때 유용하다.\n",
    "\n",
    "## 주요 활용 사례\n",
    "\n",
    "- **대화형 챗봇**: 이전 대화 내용을 기반으로 현재 질의에 적절히 응답해야 하는 경우에 사용된다.\n",
    "- **단계적 처리**: 복잡한 데이터 처리 과정에서 여러 단계를 거쳐야 할 때, 현재 단계를 처리하기 위해 이전 단계의 결과를 참조해야 하는 경우에 활용된다.\n",
    "\n",
    "## 특징\n",
    "\n",
    "- 체인이 실행될 때마다 메시지 기록을 자동으로 업데이트하여, 개발자가 별도로 기록을 관리할 필요를 줄여준다.\n",
    "- `session_id`를 기준으로 대화를 구분하며, 동일한 `session_id`를 사용하면 이전 대화의 맥락을 이어갈 수 있고, 새로운 `session_id`를 전달하면 새로운 대화로 인식한다.\n",
    "\n",
    "## 작동 원리\n",
    "\n",
    "- `Runnable` (Chain)과 `ChatMessageHistory`(메세지 저장소 객체)를 인자로 받아 생성한다.\n",
    "- 체인이 실행되면서 생성되는 대화 메시지를 저장한다.\n",
    "\n",
    "## Initializer 파라미터\n",
    "\n",
    "- **runnable**: 체인(`Runnable`) 객체이다.\n",
    "- **get_session_history**: `session_id`를 받아 해당 ID의 `ChatMessageHistory` 객체를 반환하는 함수이다. 이는 `BaseChatMessageHistory`를 상속받아 구현한 클래스의 인스턴스여야 한다.\n",
    "- **input_messages_key**: 체인의 `invoke()` 메서드 호출 시 사용자 입력 메시지를 넣을 placeholder의 이름.\n",
    "- **history_messages_key**: 채팅 기록에 저장된 메시지를 넣을 placeholder의 이름.\n",
    "\n",
    "# 메시지 저장소 (Memory - ChatMessageHistory)\n",
    "\n",
    "- **BaseChatMessageHistory**: 메시지 기록을 저장하고 관리하는 최상위 클래스. 저장 방식에 따라 이를 상속받아 다양한 클래스가 구현되어 있다.\n",
    "- **InMemoryChatMessageHistory**: 메모리에 메시지를 저장하는 클래스이다. 빠르게 메시지를 관리할 수 있지만, 애플리케이션이 종료되면 데이터가 사라진다.\n",
    "- 다양한 3rd party 저장소 연동 ChatMessageHistory 가 있다.\n",
    "    - https://python.langchain.com/docs/integrations/memory/\n",
    "\n",
    "이러한 구조를 통해 `RunnableWithMessageHistory`는 대화형 애플리케이션에서 효율적인 메시지 기록 관리와 상태 유지를 가능하게 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4435e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a348ca-ac59-4028-bc2c-0539880e519e",
   "metadata": {},
   "source": [
    "## ChatMessageHistory 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d8fe59-f0bb-45e3-a540-8436e02c281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "m_history = InMemoryChatMessageHistory() # 대화내역을 메모리에 저장.\n",
    "# 저장\n",
    "m_history.add_message((\"human\", \"안녕하세요.\"))  # Message객체\n",
    "m_history.add_message(AIMessage(\"반갑습니다.\"))\n",
    "m_history.add_message(HumanMessage(\"내 이름은 홍길동이야.\"))\n",
    "m_history.add_message(SystemMessage(\"간결하게 답하세요.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813912c1-9cb4-4769-ab1f-a60c7677cfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('human', '안녕하세요.'),\n",
       " AIMessage(content='반갑습니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='내 이름은 홍길동이야.', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='간결하게 답하세요.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 Message들 조회.\n",
    "m_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9433d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB에 메세지들을 보관. => 영구적으로 보관: SQLChatMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from sqlalchemy import create_engine # DB 연결하는 함수.\n",
    "\n",
    "engine = create_engine(\"sqlite:///chat_history.sqlite\") # 저장할 Database와 연결. SQLite - \"sqlite:///파일명\"\n",
    "\n",
    "s_history = SQLChatMessageHistory(\n",
    "    session_id=\"test_id\", \n",
    "    connection=engine\n",
    ")\n",
    "s_history.add_message(SystemMessage(\"간결하게 대답해 주세요.\"))\n",
    "s_history.add_message(HumanMessage(\"안녕하세요.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc318356-6e17-4bff-832b-451d1dc261d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='간결하게 대답해 주세요.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='안녕하세요.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_history.messages\n",
    "s_history.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71446e95-2594-44d5-bb0b-397f33336d7c",
   "metadata": {},
   "source": [
    "## RunnableWithMessageHistory를 이용해 Chain 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25c46e-ec11-41d1-85f5-13623dca5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d5cc5-5fd3-47ff-be20-274395989551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id-1': InMemoryChatMessageHistory(messages=[])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = {}  # key: session_id, \n",
    "            # value: InMemoryChatMessageHistory (session id별로 저장하는 기능이 없다.)\n",
    "def get_session_history(session_id): # ChatMessageHistory 객체를 반환하는 함수.\n",
    "    # store에서 session_id의 History객체를 찾아서 반환.\n",
    "    # 없으면 생성해서 store 저장\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    \n",
    "    return store[session_id]\n",
    "\n",
    "history_msg = get_session_history(\"id-1\")\n",
    "# history_msg\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0428775",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"질문에 대해 간결하게 대답해주세요. 정확하지 않으면 모른다고 대답하세요.\"),\n",
    "        MessagesPlaceholder(\"history\"), \n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "runnable = prompt_template | model\n",
    "\n",
    "# Chain + ChatMessageHistory => 대화 + 메세지 저장관리.\n",
    "chain = RunnableWithMessageHistory(\n",
    "    runnable=runnable, # chain 객체(RunnableSequence)\n",
    "    get_session_history=get_session_history, # session_id의 ChatMessageHistory객체를 반환하는 함수.\n",
    "    input_messages_key=\"query\", # prompt template에 입력 내용을 넣을 변수명.\n",
    "    history_messages_key=\"history\" # prompt template에 대화내역을 넣으줄 변수명\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d62af6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(\n",
    "    {\"query\":\"Langchain에 장점 세가지를 설명해줘.\"}, # 입력데이터\n",
    "    config={\"configurable\":{\"session_id\":\"id-2\"}}  # 설정 정보\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c92c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **모듈화**: Langchain은 다양한 구성 요소(모델, 데이터 소스, 체인 등)를 쉽게 조합할 수 있어 유연성과 재사용성을 높입니다.\n",
      "\n",
      "2. **다양한 데이터 소스 통합**: Langchain은 여러 데이터 소스와 API를 통합할 수 있어, 복잡한 애플리케이션을 구축할 때 유용합니다.\n",
      "\n",
      "3. **체인 구성**: 다양한 프롬프트 및 처리 단계를 체인 형태로 구성할 수 있어, 복잡한 작업을 효율적으로 처리할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6e995d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id-1': InMemoryChatMessageHistory(messages=[]),\n",
       " 'id-2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Langchain에 장점 세가지를 설명해줘.', additional_kwargs={}, response_metadata={}), AIMessage(content='1. **모듈화**: Langchain은 다양한 구성 요소(모델, 데이터 소스, 체인 등)를 쉽게 조합할 수 있어 유연성과 재사용성을 높입니다.\\n\\n2. **다양한 데이터 소스 통합**: Langchain은 여러 데이터 소스와 API를 통합할 수 있어, 복잡한 애플리케이션을 구축할 때 유용합니다.\\n\\n3. **체인 구성**: 다양한 프롬프트 및 처리 단계를 체인 형태로 구성할 수 있어, 복잡한 작업을 효율적으로 처리할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 126, 'prompt_tokens': 45, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-64f94dc0-0d76-4421-9685-442960c1e598-0', usage_metadata={'input_tokens': 45, 'output_tokens': 126, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a5579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(\n",
    "    {\"query\":\"세번째 장점에 대해 좀 더 자세하게 설명해줘.\"}, # 입력데이터\n",
    "    config={\"configurable\":{\"session_id\":\"id-2\"}}  # 설정 정보\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7dee10b-99fb-4a7c-8245-0126cedb2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain의 체인 구성 기능은 여러 개의 처리 단계를 순차적으로 연결하여 복잡한 작업을 수행할 수 있도록 합니다. 사용자는 각 단계에서 특정 작업을 정의하고, 그 결과를 다음 단계의 입력으로 사용할 수 있습니다. \n",
      "\n",
      "예를 들어, 데이터 수집, 전처리, 모델 예측, 후처리 등의 과정을 체인으로 구성할 수 있습니다. 이렇게 하면 각 단계의 결과가 자동으로 다음 단계에 전달되며, 전체 프로세스를 간소화하고 명확하게 관리할 수 있습니다. \n",
      "\n",
      "또한, 체인은 쉽게 수정하거나 확장할 수 있어, 새로운 기능이나 알고리즘을 추가할 때 유용합니다. 이를 통해 개발자는 복잡한 애플리케이션을 보다 효율적으로 구축하고 유지관리할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c9c6b-bd59-4f85-9203-e3ea4ce0cc94",
   "metadata": {},
   "source": [
    "# RunnableWithMessageHistory + Memory class\n",
    "\n",
    "- Memory class로 저장 방식 설정\n",
    "- BaseChatMessageHistory로 어디에 저장할 지 설정\n",
    "- RunnableWithMessageHistory로 chain 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "963a5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22f9d4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id-1': InMemoryChatMessageHistory(messages=[]),\n",
       " 'id-2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Langchain에 장점 세가지를 설명해줘.', additional_kwargs={}, response_metadata={}), AIMessage(content='1. **모듈화**: Langchain은 다양한 구성 요소(모델, 데이터 소스, 체인 등)를 쉽게 조합할 수 있어 유연성과 재사용성을 높입니다.\\n\\n2. **다양한 데이터 소스 통합**: Langchain은 여러 데이터 소스와 API를 통합할 수 있어, 복잡한 애플리케이션을 구축할 때 유용합니다.\\n\\n3. **체인 구성**: 다양한 프롬프트 및 처리 단계를 체인 형태로 구성할 수 있어, 복잡한 작업을 효율적으로 처리할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 126, 'prompt_tokens': 45, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-64f94dc0-0d76-4421-9685-442960c1e598-0', usage_metadata={'input_tokens': 45, 'output_tokens': 126, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='세번째 장점에 대해 좀 더 자세하게 설명해줘.', additional_kwargs={}, response_metadata={}), AIMessage(content='Langchain의 체인 구성 기능은 여러 개의 처리 단계를 순차적으로 연결하여 복잡한 작업을 수행할 수 있도록 합니다. 사용자는 각 단계에서 특정 작업을 정의하고, 그 결과를 다음 단계의 입력으로 사용할 수 있습니다. \\n\\n예를 들어, 데이터 수집, 전처리, 모델 예측, 후처리 등의 과정을 체인으로 구성할 수 있습니다. 이렇게 하면 각 단계의 결과가 자동으로 다음 단계에 전달되며, 전체 프로세스를 간소화하고 명확하게 관리할 수 있습니다. \\n\\n또한, 체인은 쉽게 수정하거나 확장할 수 있어, 새로운 기능이나 알고리즘을 추가할 때 유용합니다. 이를 통해 개발자는 복잡한 애플리케이션을 보다 효율적으로 구축하고 유지관리할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 193, 'total_tokens': 363, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-31a1d534-d7ce-4557-93b8-608672176480-0', usage_metadata={'input_tokens': 193, 'output_tokens': 170, 'total_tokens': 363, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a278bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "config = {\"configurable\": {\"session_id\":\"chat_message_1\"}}\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    \n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "        return store[session_id]\n",
    "    \n",
    "    memory = ConversationBufferWindowMemory(\n",
    "        chat_memory=store[session_id], # 메세지 저장소 추가.\n",
    "        k=2,\n",
    "        return_messages=True,\n",
    "        message_key=\"history\"\n",
    "    )\n",
    "    # 1. memory에서 저장된 message들을 조회\n",
    "    message_list = memory.load_memory_variables({})['history']# list[Message]\n",
    "    # 2. 조회한 message들을 InMemoryChatMessageHistory에 추가\n",
    "    store[session_id] = InMemoryChatMessageHistory(messages=message_list)\n",
    "    # 3. 2의 InMemoryChatMessageHistory를 반환.\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "646d0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"질문에 대해 간결하게 대답해주세요. 정확하지 않으면 모른다고 대답하세요.\"),\n",
    "        MessagesPlaceholder(\"history\"), \n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "runnable = prompt_template | model\n",
    "\n",
    "# Chain + ChatMessageHistory => 대화 + 메세지 저장관리.\n",
    "chain = RunnableWithMessageHistory(\n",
    "    runnable=runnable, # chain 객체(RunnableSequence)\n",
    "    get_session_history=get_session_history, # session_id의 ChatMessageHistory객체를 반환하는 함수.\n",
    "    input_messages_key=\"query\", # prompt template에 입력 내용을 넣을 변수명.\n",
    "    history_messages_key=\"history\" # prompt template에 대화내역을 넣으줄 변수명\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b41f1b8-8ab8-4b4d-a3ae-ab57b102d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"query\":\"내 이름은 홍길동입니다. 나는 20세 입니다.\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "146021f2-bd39-4781-b7db-0f381b8ebf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='반갑습니다, 홍길동님! 20세라니 젊으시군요. 도움이 필요하시면 말씀해 주세요.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 47, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_818c284075', 'finish_reason': 'stop', 'logprobs': None} id='run-00d303a9-5054-4576-8e70-d194f2439dc5-0' usage_metadata={'input_tokens': 47, 'output_tokens': 29, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b1bb2f5-c4c7-4b76-98ee-083cf50e5dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_message_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='내 이름은 홍길동입니다. 나는 20세 입니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='반갑습니다, 홍길동님! 20세라니 젊으시군요. 도움이 필요하시면 말씀해 주세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 47, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_818c284075', 'finish_reason': 'stop', 'logprobs': None}, id='run-00d303a9-5054-4576-8e70-d194f2439dc5-0', usage_metadata={'input_tokens': 47, 'output_tokens': 29, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "481ada28",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"query\":\"내가 몇살인가요?\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5524db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='20세라고 하셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 91, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-26b48777-ff7d-40cb-8dc0-db2ddfd4495e-0', usage_metadata={'input_tokens': 91, 'output_tokens': 7, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc2f46ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_message_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='내 이름은 홍길동입니다. 나는 20세 입니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, 홍길동님! 만나서 반갑습니다. 20세시군요. 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 47, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-daf9573d-a895-48f1-944c-6973f3178c2e-0', usage_metadata={'input_tokens': 47, 'output_tokens': 29, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내가 몇살인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='20세입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 91, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-8b060fc8-7042-463f-bafc-691fd153b65e-0', usage_metadata={'input_tokens': 91, 'output_tokens': 4, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34d712d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"query\":\"내 이름은 무엇인가요?\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db111161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 이름은 홍길동입니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efa05a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_message_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='내 이름은 홍길동입니다. 나는 20세 입니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, 홍길동님! 만나서 반갑습니다. 20세시군요. 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 47, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-daf9573d-a895-48f1-944c-6973f3178c2e-0', usage_metadata={'input_tokens': 47, 'output_tokens': 29, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내가 몇살인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='20세입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 91, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-8b060fc8-7042-463f-bafc-691fd153b65e-0', usage_metadata={'input_tokens': 91, 'output_tokens': 4, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내 이름은 무엇인가요?', additional_kwargs={}, response_metadata={}), AIMessage(content='홍길동입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 110, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3de1288069', 'finish_reason': 'stop', 'logprobs': None}, id='run-b2bd0853-2c38-4daa-adfe-889a7c752292-0', usage_metadata={'input_tokens': 110, 'output_tokens': 5, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64f58a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"query\":\"내 이름과 나이를 다시 알려주세요?\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00f02990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='죄송하지만, 당신의 이름과 나이를 알고 있지 않습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 89, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d11a804b-e91f-492e-be10-8752d8209a99-0', usage_metadata={'input_tokens': 89, 'output_tokens': 15, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95867749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='내가 몇살인가요?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='20세라고 하셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 91, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-26b48777-ff7d-40cb-8dc0-db2ddfd4495e-0', usage_metadata={'input_tokens': 91, 'output_tokens': 7, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " HumanMessage(content='내 이름은 무엇인가요?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='당신의 이름은 홍길동입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 113, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cb28854-b887-47f0-9cbf-e7a7f7efb580-0', usage_metadata={'input_tokens': 113, 'output_tokens': 10, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " HumanMessage(content='내 이름과 나이를 다시 알려주세요?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='죄송하지만, 당신의 이름과 나이를 알고 있지 않습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 89, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d11a804b-e91f-492e-be10-8752d8209a99-0', usage_metadata={'input_tokens': 89, 'output_tokens': 15, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(store['chat_message_1'].messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
