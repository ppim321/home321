{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907e923a-af5e-48c3-9664-58bd640efb20",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "![rag_embedding](figures/rag_embedding.png)\n",
    "\n",
    "- 분할된 텍스트를 벡터 표현(임베딩 벡터)으로 변환한다.\n",
    "- LangChain은 OpenAI, HuggingFace 등 다양한 임베딩 모델을 지원하며, 동일한 인터페이스로 사용할 수 있다.\n",
    "- [임베딩모델의 메서드](https://api.python.langchain.com/en/latest/embeddings/langchain_core.embeddings.embeddings.Embeddings.html#langchain_core.embeddings.embeddings.Embeddings)\n",
    "\n",
    "    - **`embed_documents(texts: List[str])`**\n",
    "        - 여러 문서를 받아 벡터화(임베딩)한다.\n",
    "        - Context를 벡터화 할 때 사용한다.\n",
    "    - **`embed_query(text: str)`**\n",
    "        - 하나의 문자열(문서)을 받아 벡터화한다.\n",
    "        - Query를 벡터화 할 때 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff941301-56f5-4219-89e8-6b54d5afd7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be279b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.20 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-ollama) (0.3.21)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-ollama) (0.4.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from ollama<1,>=0.3.0->langchain-ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install langchain-ollama\n",
    "#pip show langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9924a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-huggingface\n",
      "Version: 0.1.2\n",
      "Summary: An integration package connecting Hugging Face and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\langchain\\Lib\\site-packages\n",
      "Requires: huggingface-hub, langchain-core, sentence-transformers, tokenizers, transformers\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465811fa-32dd-44f3-96f9-c6193cb414ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baec36fc-588d-4991-bf61-34d2e16851fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://platform.openai.com/docs/models#embeddings\n",
    "# embedding_model_name = \"text-embedding-3-small\"\n",
    "# embedding_model = OpenAIEmbeddings(\n",
    "#     model=embedding_model_name\n",
    "# )\n",
    "\n",
    "\n",
    "# ## HuggingFace의  Embeddings 모델 사용\n",
    "# # huggingface.co : Models => task:NLP - Feature Extraction task를 선택\n",
    "# embedding_model_name = \"BAAI/bge-m3\"\n",
    "# embedding_model = HuggingFaceEmbeddings(\n",
    "#     model_name = embedding_model_name\n",
    "# )\n",
    "\n",
    "## Ollama의  Embeddings 모델 사용\n",
    "### ollama.com\n",
    "embedding_model_name = \"nomic-embed-text\"\n",
    "embedding_model = OllamaEmbeddings(\n",
    "    model=embedding_model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24cccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e539ca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 문장(문서)들을 Embedding Vector로 변환\n",
    "text_list = [\n",
    "        \"The meaning of COW is the mature female of cattle (genus Bos).\",\n",
    "        \"A puppy is a juvenile dog.\",\n",
    "        \"Which one is correct, 'many people' or 'much people'?\",\n",
    "        \"Book your Amtrak train and bus tickets today by choosing from over 30 U.S.\",\n",
    "]\n",
    "embedding_docs = embedding_model.embed_documents(text_list)\n",
    "print(len(embedding_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6398b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n",
      "embedding vector의 차원수: 768\n"
     ]
    }
   ],
   "source": [
    "print(type(embedding_docs), type(embedding_docs[0]))\n",
    "print(\"embedding vector의 차원수:\", len(embedding_docs[0]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8796f97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0099094855,\n",
       " 0.042601053,\n",
       " -0.1549793,\n",
       " -0.05094128,\n",
       " 0.07207404,\n",
       " 0.038724188,\n",
       " -0.0276544,\n",
       " -0.026862217,\n",
       " -0.057049092,\n",
       " -0.03338403]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_docs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80933fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 768\n"
     ]
    }
   ],
   "source": [
    "# 질문 -> Embedding Vector \n",
    "query = \"How much the bus ticket price?\"\n",
    "embedding_query = embedding_model.embed_query(query) # 한 문장을 변환.\n",
    "print(type(embedding_query), len(embedding_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8978fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도 계산 함수\n",
    "import numpy as np\n",
    "def cosine_similarity(v1:np.ndarray|list, v2:np.ndarray|list)->float:\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# np.linalg.norm(v1) \n",
    "# (v1) = [2, 3, 5]\n",
    "# np.sqrt(2**2 + 3**2 + 5**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a539b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.29334711657233364\n",
      "1 0.32038168592552274\n",
      "2 0.3805105991454101\n",
      "3 0.6073879825242146\n"
     ]
    }
   ],
   "source": [
    "for i, e_vector in enumerate(embedding_docs):\n",
    "    print(i, cosine_similarity(e_vector, embedding_query)) # 각 문서 - 질문 간의 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d02707-99d9-4d48-826f-ae446a405fc6",
   "metadata": {},
   "source": [
    "# 벡터 데이터베이스(Vector Database)\n",
    "- Embedding 된 문서를 Vector Database(Vector Store)에 저장한다.\n",
    "- 이후 질문(Query)와 관련된 내용을 유사도를 이용해 검색해 질문과 함께 prompt로 만든다. (Retrieve)\n",
    "\n",
    "![rag_vector_store](figures/rag_vector_store.png)\n",
    "\n",
    "## 벡터 데이터베이스란\n",
    "- 벡터 임베딩을 저장하고 관리하는 데이터베이스를 의미한다.\n",
    "- 모든 데이터는 적절한 임베딩 모델을 활용하면 임베딩 벡터로 변환할 수 있다. 이렇게 변환된 임베딩 벡터를 벡터 데이터베이스에 저장하면 **임베딩 벡터 간의 거리 계산을 통해 데이터 간 유사도를 검색할 수 있다.**\n",
    "    - 이미지, 텍스트, 음성 등 비정형 데이터를 임베딩 모델로 벡터화한 뒤 데이터베이스에 저장한다.\n",
    "    - 벡터 간의 유사도 계산을 통해 연관성 있는 데이터나 유사한 데이터를 효과적으로 검색할 수 있다.\n",
    "    - 좋은 검색 결과를 위해서는 벡터의 품질이 중요하다. 그래서 **임베딩 모델(Embedding Model)을 잘 선택하는 것이 중요**하다.\n",
    "- 벡터 데이터베이스는 이러한 벡터 간 거리 계산에 특화된 데이터베이스다.\n",
    "\n",
    "## 주요 특징\n",
    "\n",
    "- 고차원 벡터 저장\n",
    "  -  벡터 데이터베이스는 수백에서 수천 차원에 이르는 벡터 데이터를 효율적으로 저장하고 관리한다. \n",
    "  -  전통적인 데이터베이스로는 어려운 고차원 벡터 간 유사도 검색을 효율적으로 수행한다.\n",
    "- 유사성 기반 검색\n",
    "  -  벡터 간의 거리를 측정하여 유사한 데이터를 빠르게 검색할 수 있다. \n",
    "  -  일반적으로 사용되는 거리계산기법은 다음과 같다.\n",
    "     - 코사인 유사도(Cosine Similarity)\n",
    "     - 유클리드 거리(Euclidean Distance)\n",
    "     - 맨하탄 거리(Manhattan Distance) \n",
    "- 비정형 데이터 처리: 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 변환하여 저장하고, 이러한 데이터를 효과적으로 검색할 수 있다.\n",
    "\n",
    "## 벡터 데이터베이스와 딥러닝\n",
    "- 벡터 데이터베이스는 딥러닝 기술의 발전과 깊은 관련이 있다.\n",
    "- 딥러닝 모델은 학습 과정에서 데이터의 특징을 추출하는 방법을 함께 학습한다. 충분한 데이터를 학습한 딥러닝 모델은 데이터의 특성을 추론하기 위한 **특성 벡터(feature vector)**를 효과적으로 생성할 수 있다.\n",
    "- 이때 추출된 특성 벡터는 고차원 데이터를 저차원 공간에서 표현한 **임베딩 벡터**다.\n",
    "    - > **임베딩**은 고차원 데이터를 저차원 공간으로 변환하여 표현하는 방법으로, 정보 손실을 최소화하면서 데이터 간의 의미 있는 관계를 벡터 공간에서 유지한다.\n",
    "- 딥러닝 모델로 추출한 데이터의 특징을 임베딩 공간에 배치하면, 비슷한 데이터는 가까이, 그렇지 않은 데이터는 멀리 배치된다.\n",
    "- 이러한 특성을 활용하면 임베딩 벡터 간의 거리를 계산해 유사한 데이터를 효과적으로 검색할 수 있다. 벡터 데이터베이스는 이러한 임베딩 벡터의 특성을 기반으로 개발되었다.\n",
    "- 딥러닝 기술의 발전과 폭넓은 활용으로 임베딩 데이터의 사용이 증가하면서, 이를 저장하고 관리하는 기능에 특화된 데이터베이스에 대한 수요도 증가해 다양한 벡터 데이터베이스가 등장했다.\n",
    "\n",
    "## 벡터 데이터베이스의 주요 기능\n",
    "1. **저장**  \n",
    "   - 이미지, 텍스트, 음성 등 **비정형 데이터**를 임베딩 모델을 통해 벡터로 변환한 뒤 벡터 데이터베이스에 저장한다.\n",
    "2. **검색**  \n",
    "   - 검색하려는 데이터를 임베딩 모델로 변환한 뒤, 벡터 데이터베이스에서 유사도를 기반으로 검색한다.\n",
    "3. **결과 반환**  \n",
    "   - 벡터 데이터베이스는 저장된 벡터 중 검색 쿼리 임베딩과 가장 가까운 벡터를 찾아 반환한다.\n",
    "\n",
    "## LLM과 벡터 데이터베이스\n",
    "- ChatGPT의 등장 이후 벡터 데이터베이스는 폭발적인 주목을 받았다.\n",
    "- 임베딩 벡터의 유사도를 기반으로 문서를 검색하는 RAG(Relevant Augmented Generation) 기술은 LLM의 환각(할루시네이션) 현상을 줄이고, LLM을 추가 학습하지 않고도 최신 정보를 효율적으로 활용할 수 있는 핵심 기법으로 자리 잡았다.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65063-9482-4fdb-9ada-941eb08fb3b2",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 종류\n",
    "![img](figures/vector_database.png)\n",
    "\n",
    "<<https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c>>\n",
    "\n",
    "### 주요 벡터 데이터베이스 종류\n",
    "- **Pinecone**\n",
    "    - 클라우드 기반의 완전 관리형 벡터 데이터베이스 서비스로, 간단한 API를 통해 벡터 데이터를 관리할 수 있다.  \n",
    "    - 자동 확장성과 고가용성을 제공하며, 실시간 데이터 수집과 유사성 검색에 최적화되어 있다.\n",
    "    - 가장 쉽게 시작할 수 있는 관리형 서비스를 제공한다.\n",
    "- **Chroma**\n",
    "    - 벡터 임베딩을 효율적으로 저장하고 검색할 수 있는 오픈소스 데이터베이스로, AI 및 머신러닝 애플리케이션에 최적화되어 있다.\n",
    "    - 대규모 임베딩 저장에 최적화되어 있다.\n",
    "- **FAISS**\n",
    "    - Facebook AI에서 개발한 고성능 벡터 검색 라이브러리로, 고차원 벡터의 효율적인 유사성 검색을 위해 최적화되어 있다.\n",
    "    - GPU를 활용해 계산 성능을 높이며, 벡터 양자화 기술을 활용하여 메모리 사용을 최적화한다.\n",
    "    - 근사 최근접 이웃 검색(ANNS)에 최적화되어 있다.\n",
    "- **Milvus**\n",
    "    - 오픈소스 벡터 데이터베이스로, 대규모 벡터 데이터를 효율적으로 저장하고 검색할 수 있다.  \n",
    "    - 분산 아키텍처를 채택하여 확장성이 뛰어나며, IVF_PQ, DiskANN 등 다양한 인덱싱 알고리즘을 지원한다.\n",
    "    - 대규모 데이터셋 처리에 가장 적합한 솔루션이다.\n",
    "- **Weaviate**\n",
    "    - 오픈소스 벡터 데이터베이스로, 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 저장하고 검색할 수 있다.  \n",
    "    - GraphQL API를 통해 접근 가능하며, 내장된 머신러닝 모듈을 통해 가장 강력한 의미론적 검색 기능을 제공한다.\n",
    "- **Qdrant**\n",
    "    - Rust로 개발된 고성능 벡터 검색 엔진으로, 실시간 근사 최근접 이웃 검색을 제공한다.  \n",
    "    - 추천 시스템에 특화되어 있으며, 벡터 임베딩 저장과 유사도 쿼리를 효율적으로 수행한다.\n",
    "- **Elasticsearch**\n",
    "    - HNSW 알고리즘을 사용하여 벡터 검색을 구현하는 검색 엔진이다.\n",
    "    - 전통적인 검색 기능과 벡터 검색을 효과적으로 결합할 수 있어, 하이브리드 검색에 가장 적합하다.\n",
    "- **PGVector**\n",
    "    - PostgreSQL의 확장 모듈로, 벡터 데이터를 저장하고 유사성 검색을 수행할 수 있게 해준다.  \n",
    "    - SQL과 통합된 벡터 연산이 가능하며, L2 거리, 코사인 거리, 내적 등 다양한 거리 측정 방식을 지원한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3f6fe-c5e2-4c4f-9ef8-2cf5850f1bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1336f523-0b76-419c-8e46-fa96bdbcbdd6",
   "metadata": {},
   "source": [
    "# Langchain - Vector Store 연동 \n",
    "- Langchain은 다양한 벡터 데이터베이스와 연동할 수 있다.\n",
    "- 벡터 데이터베이스 마다 API가 다르기 때문에, Langchain을 사용하면 동일한 interface로 사용할 수 있다.\n",
    "\n",
    "## **VectorStore**\n",
    "- Langchain이 지원하는 모든 벡터 데이터베이스는 **VectorStore** 인터페이스를 구현한다.\n",
    "- 그래서 Langchain에서는 벡터 데이터베이스를 **Vector Store** 라고 한다.\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "## InMemoryVectorStore\n",
    "- langchain-core에서 제공하는 메모리 기반 벡터 데이터베이스이다.\n",
    "- Data들을 Dictionary를 사용해 메모리에 저장하며, 검색 할 때 코사인 유사도(cosine similarity)를 계산하여 조회한다.\n",
    "- 설치\n",
    "  - `pip install -qU langchain-core`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fcddfb-0fd3-4cb8-a4f0-b72d1988d6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e308d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embedding_model=OpenAIEmbeddings(model= \"text-embedding-3-small\")\n",
    "vector_store = InMemoryVectorStore(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfa2a05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "doc_1 = Document(id=\"1\", page_content=\"Apple, Pear, Watermelon\", metadata={\"category\":\"Fruit\"})\n",
    "\n",
    "doc_2 = Document(id=\"2\", page_content=\"Pyton, C++, Javam C#\", metadata={\"category\":\"IT\"})\n",
    "\n",
    "doc_3 = Document(id=\"3\", page_content=\"Football, Baseball, Basketball\", metadata={\"category\":\"Sports\"})\n",
    "\n",
    "# Document 들을 List로 묶어준다.\n",
    "docs = [doc_1, doc_2, doc_3]\n",
    "\n",
    "# Vector Store에 문서들을 저장 -> page_content를 embedding해서 저장. metadata, id는 그대로 저장.\n",
    "vector_store.add_documents(documents=docs)\n",
    "\n",
    "# 1. Vector Store 생성.   2. 생성된 Vector Store 에 데이터를 저장(추가)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afbc4641-857c-47c1-80ff-5f4c2651a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Vector Store를 데이터에 추가하면서 생성.\n",
    "vector_store2 = InMemoryVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3b4600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 -> 유사도 검색\n",
    "query = \"SQL\"\n",
    "query = \"Rust\"\n",
    "query = \"Orange\"\n",
    "query = \"Volleyball\"\n",
    "query = \"House\"\n",
    "# result = vector_store.similarity_search(\n",
    "result = vector_store.similarity_search_with_score(  # 유사도 점수를 포함해서 리턴.\n",
    "    query=query,   # 검색 대상 문자열\n",
    "    k=2,           # 유사도가 높은 순서대로 지정한 갯수의 데이터를 반환함.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ea64542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='1', metadata={'category': 'Fruit'}, page_content='Apple, Pear, Watermelon'),\n",
       "  0.1622070321836628),\n",
       " (Document(id='3', metadata={'category': 'Sports'}, page_content='Football, Baseball, Basketball'),\n",
       "  0.1518558798832099)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da7c8f-c1be-4ddf-a935-90b22eac1f11",
   "metadata": {},
   "source": [
    "# 실습\n",
    "- data/olympic.txt \n",
    "1. loading\n",
    "2. split\n",
    "3. embedding + vector store(InMemoryVectorStore)에 저장\n",
    "4. query(질의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349be3ce-539e-4d18-bc2b-67e8100ebcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca79ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "# TextLoader 로 document loading\n",
    "\n",
    "path =\"data/olympic.txt\"\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "load_docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91867fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveTextCharacterTextSplitter.from_titoken_encoder()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\",  \n",
    "    chunk_size=500,   \n",
    "    chunk_overlap=100,\n",
    ")\n",
    "docs = splitter.split_documents(load_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "#### load와 split 을 한번에 처리\n",
    "\n",
    "path =\"data/olympic.txt\"\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\",  \n",
    "    chunk_size=500,   \n",
    "    chunk_overlap=100,\n",
    ")\n",
    "docs = loader.load_and_split(splitter)\n",
    "print(len(docs))\n",
    "\n",
    "# docs list[document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InMemoryVectorStore 생성 및 저장\n",
    "## 생성과 저장을 한번에 처리  \n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    embedding=embedding_model,\n",
    "    documents=docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "152a3ac6-6f56-41ea-9c60-6a982226eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_search()를 이용해서 질문과 관련된 문서들을 조회.\n",
    "\n",
    "# query = \"동계 올림픽에 대해 설명해주세요.\"\n",
    "query = \"올림픽에 금메달을 가장 많이 획득한 선수를 알려주세요.\"\n",
    "result = vector_store.similarity_search_with_score(\n",
    "    query=query,  \n",
    "    k=3,          \n",
    ")\n",
    "# result : list[tuple[Document, 점수]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도점수: 0.48681135541523596\n",
      "올림픽은 거의 모든 국가가 참여할 정도로 규모가 커졌다. 하계 올림픽은 33개의 종목과 약 400개의 세부종목에서 13,000명이 넘는 선수들이 겨루고 그중 각 종목별 1, 2, 3위는 각각 금/은/동을 수여받는다. 전 세계 언론에서 각각 4년마다 열리는 올림픽 경기를 중계하기 때문에 이름 없는 선수가 개인적, 국가적, 세계적으로 명성을 얻을 수 있는 기회가 된다. 이와 더불어 올림픽 경기는 개최지와 개최국에게도 전 세계에 그 이름을 널리 알리는 좋은 기회가 된다.\n",
      "=======================================================\n",
      "유사도점수: 0.4528750282777687\n",
      "올림픽\n",
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다. 대부분의 인기있는 종목들이나 일상에서 쉽게 접하고 즐길 수 있는 생활스포츠 종목들이 올림픽이라는 한 대회에서 동시에 열리고, 전 세계 대부분의 국가 출신의 선수들이 참여하는 만큼 전 세계 스포츠 팬들이 가장 많이 시청하는 이벤트이다. 2008 베이징 올림픽의 모든 종목 누적 시청자 수만 47억 명에 달하며, 이는 인류 역사상 가장 많은 수의 인구가 시청한 이벤트였다.\n",
      "=======================================================\n",
      "유사도점수: 0.44542856400060976\n",
      "우승자와 메달리스트\n",
      "개인 혹은 팀으로 경기에 출전해서 1위, 2위, 3위를 한 선수는 메달을 받는다. 1912년까지는 우승자에게 순금으로 된 금메달을 주었으며 그 후에는 도금된 금메달을 준다. 하지만, 2010 동계 올림픽에서는 전자제품 부속품을 녹여서 넣었다. 이러한 경우처럼 순금 외에 다른 물질을 넣을 경우에는 순금이 반드시 6g 이상을 함유하고 있어야 한다. 2위를 한 선수는 은메달을, 3위를 한 선수는 동메달을 받는다. 토너먼트로 진행되는 종목의 경우에는(복싱, 태권도 등) 3위를 구분하지 않고 준결승에서 패해서 3/4위전으로 간 선수들에게 모두 동메달을 수여한다. 1896년 하계 올림픽에서는 메달이 2개만 수여됐는데 1위에게 은메달을 주었고 2위에게 동메달을 주었다. 이때 3위에게는 아무것도 없었다. 현재의 메달 수여 방식은 1904년 하계 올림픽 때부터 시작되었다. 1948년부터는 4, 5, 6위를 한 선수에게는 인증서를 수여했다. 1984년 대회부터는 7, 8위를 한 선수에게도 인증서를 수여했다. 아테네에서 열린 2004년 하계 올림픽 때는 1, 2, 3위 선수에게 메달과 함께 올리브 화환도 같이 수여했다. 국가 올림픽 위원회(NOC)와 방송사에서는 자국의 메달 현황을 실시간으로 전달하기도 한다.\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "for document, score in result:\n",
    "    print(\"유사도점수:\", score)\n",
    "    print(document.page_content[:1000])\n",
    "    print(\"=======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d01f0-2fd7-4795-85a1-4ce9ea26a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  가입 pinecone.io  API_KEY= pcsk_2njnCS_GoMZL8KPbqYbPuJeuQVAdkz2u4qcpVxHHNkQRUrrzD7vZdrZGnn6QnUWe6CwMVu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c15ed2-e9d6-4361-9d9e-0dfaf650de41",
   "metadata": {},
   "source": [
    "## MMR(최대 한계 관련성-Maximal Marginal Relevance) 알고리즘 적용\n",
    "최대 한계 관련성(Maximal Marginal Relevance, MMR) 알고리즘은 정보 검색 및 요약에서 검색 결과의 **관련성**과 **다양성**을 동시에 고려하여 최적의 결과를 제공하는 방법이다. \n",
    "이 알고리즘은 사용자 쿼리와의 관련성을 최대화하면서도 중복 정보를 최소화하여 다양한 정보를 제공하는 것을 목표로 한다.\n",
    "\n",
    "1. **관련성과 다양성의 균형 조절**: MMR은 사용자 쿼리와 문서 간의 유사성 점수와 이미 선택된 문서들과의 다양성 점수를 조합하여 각 문서의 최종 점수를 계산한다. 이를 통해 관련성이 높으면서도 중복되지 않는 문서를 선택한다.\n",
    "\n",
    "2. **수학적 정의**: MMR은 다음과 같이 정의됩니다:\n",
    "   $$\n",
    "   \\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')\n",
    "   $$\n",
    "\n",
    "   - $\\text{Sim}(d, Q)$: 문서 $d$와 쿼리 $\\text{Q}$ 사이의 유사성. (문서 유사성 계산)\n",
    "   - $\\max_{d' \\in D'} \\text{Sim}(d, d')$: 문서 $d$와 이미 선택된 문서 집합 $D'$ 중 가장 유사한 문서와의 유사성. (문서 다양성 계산)\n",
    "   - $\\lambda$: 유사성과 다양성의 중요도를 조절하는 매개변수(parameter)\n",
    "3. **적용 분야**: MMR은 정보 검색, 추천 시스템, 문서 요약 등에서 활용된다. 특히 LLM 검색에서 성능 향상이 입증되었다.\n",
    "\n",
    "### `vectorStore.max_marginal_relevance_search()` 메소드\n",
    "  - MMR 알고리즘을 적용한 검색을 수행한다.\n",
    "  - **파라미터**\n",
    "    - **query**: 사용자로부터 입력받은 검색 쿼리\n",
    "    - **k**: 최종적으로 선택할 문서의 수\n",
    "    - **fetch\\_k**: MMR 알고리즘 적용 시 고려할 상위 문서의 수\n",
    "    - **lambda_mult**: 쿼리와의 유사성과 선택된 문서 간의 다양성 사이의 균형을 조절하는 매개변수. $\\lambda = 1$이면 유사성만 고려하고, $\\lambda = 0$이면 다양성만을 최대화한다.\n",
    "    - **filter**: 검색 결과를 필터링할 조건을 지정한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a398d-f0f6-416f-aad8-4c97ced68992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b3c9c-8f56-48fd-a952-9f79f0b75f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab46f5a-14b4-4b0d-a6ea-4dd855a452c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
